"""En este script buscamos reducciones de dimensionales con el objetivo de evitar posibles problemas con alta dimensionalidad.Además, el buen resultado visto con las merged columns motiva también esta reducción de la dimensionalidad.Primero, se probará con PCA. PCA está diseñado para ser ejecutado realizando una estandarización previa.  De esta manera, todas las variablestienen la misma importancia en el PCA. Sin embargo, también se probará con el robustScaler en vista de sus buenos resultados. Se pedirá que el número de componentes encontradas tengan al menos el 90 % de la varianza total de los datos. Nota:Para el RobustScaler se llegará a este porcentaje con menor número de componentes al estar ponderadas las variables de manera diferente,se debería de escoger un umbral mayor para este caso)Después, se prueba con LDA/QDA basándonos en las merged columns encontradas en el EDA."""import osimport sysMODELS = os.path.abspath(os.path.join(os.path.dirname(__file__), os.pardir))SRC = os.path.abspath(os.path.join(MODELS, os.pardir))sys.path.append(SRC)import utilsimport numpy as npimport pandas as pdfrom sklearn.neighbors import KNeighborsClassifierfrom sklearn.model_selection import cross_validatefrom sklearn.model_selection import GridSearchCVfrom sklearn.preprocessing import RobustScalerfrom sklearn.preprocessing import StandardScalerfrom sklearn.decomposition import PCAfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysisimport TGAtrain_raw = utils.load_train()train_X = utils.one_hot_encode(df = train_raw.drop(["Transported", "PassengerId"], axis = 1))"""#-------------- Con robust scaler ------------------------RobScal = RobustScaler()colnames = train_X.columnsdf_array = RobScal.fit_transform(train_X)train_X_RobScaled = pd.DataFrame(df_array,columns=colnames)pca = PCA(n_components=train_X.shape[1])pca.fit(train_X_RobScaled)ratios = pca.explained_variance_ratio_for i in range(train_X.shape[1]):  if np.cumsum(ratios)[i] >= 0.9:    num_pca_RobS = i + 1    print ("El número mínimo de PCA's para RobustScaler llegue al 90% de varianza: {}".format(num_pca_RobS))    break#---------------- Con Standard Scaler------------------StandScal = StandardScaler()colnames = train_X.columnsdf_array = StandScal.fit_transform(train_X)train_X_SdScaled = pd.DataFrame(df_array,columns=colnames)pca = PCA(n_components=train_X.shape[1], random_state = 1)pca.fit(train_X_SdScaled)ratios = pca.explained_variance_ratio_for i in range(train_X.shape[1]):  if np.cumsum(ratios)[i] >= 0.9:    num_pca_SS = i + 1    print ("El número mínimo de PCA's para StandardScaler llegue al 90% de varianza: {}\n".format(num_pca_SS))    breaktrain_X_PCA = PCA(n_components = 15, random_state=1).fit_transform(train_X_RobScaled)train_y = train_raw.Transportedprint('CV Score, Optimum_K, p')#------------------------------PCA's con RobustScaler-------------------------------for components in range(num_pca_RobS,20):    pca = PCA(n_components = components, random_state=1)    train_X_PCA = pca.fit_transform(train_X_RobScaled)    print(" ·",components,'components, explained variance:',np.round(np.cumsum(pca.explained_variance_ratio_)[components-1],7))    for p_ in [1,2]:        optim_score = 0        for k in range(1,100):                score_cv = cross_validate(estimator = KNeighborsClassifier(n_neighbors=k,p = p_),                                      X = train_X_PCA, y = train_y, cv = 10, n_jobs = -1)                        score_test = np.mean(score_cv["test_score"])                        if score_test > optim_score:                optim_score = score_test                k_optim = k                p_optim = p_                print("%.5f,%.d,%.d"%(optim_score,k_optim, p_optim))#------------------------------PCA's con StandardScaler-------------------------------for components in range(num_pca_SS,20):    pca = PCA(n_components = components, random_state=1)    train_X_PCA = pca.fit_transform(train_X_SdScaled)    print(" ·",components,'components, explained variance:',np.round(np.cumsum(pca.explained_variance_ratio_)[components-1],7))    for p_ in [1,2]:        optim_score = 0        for k in range(1,100):                score_cv = cross_validate(estimator = KNeighborsClassifier(n_neighbors=k,p = p_),                                      X = train_X_PCA, y = train_y, cv = 10, n_jobs = -1)                        score_test = np.mean(score_cv["test_score"])                        if score_test > optim_score:                optim_score = score_test                k_optim = k                p_optim = p_                print("%.5f,%.d,%.d"%(optim_score,k_optim, p_optim))#----------------------------LDA con RobustScaler----------------------print('\n LDA con RobustScaler:')lda_RS = LinearDiscriminantAnalysis()   train_X_LDA = lda_RS.fit_transform(train_X_RobScaled,train_y)optim_score = 0for p_ in [1,2]:       for k in range(1,100):        score_cv = cross_validate(estimator = KNeighborsClassifier(n_neighbors=k,p = p_),                                          X = train_X_LDA, y = train_y, cv = 10, n_jobs = -1)                        score_test = np.mean(score_cv["test_score"])                        if score_test > optim_score:            optim_score = score_test            k_optim = k            p_optim = p_        print("%.5f,%.d,%.d"%(optim_score,k_optim, p_optim))#----------------------------LDA con StandardScaler----------------------print('\n LDA con StandardScaler:')lda_SS = LinearDiscriminantAnalysis()   train_X_LDA = lda_SS.fit_transform(train_X_SdScaled,train_y)optim_score = 0for p_ in [1,2]:       for k in range(1,100):        score_cv = cross_validate(estimator = KNeighborsClassifier(n_neighbors=k,p = p_),                                          X = train_X_LDA, y = train_y, cv = 10, n_jobs = -1)                        score_test = np.mean(score_cv["test_score"])                        if score_test > optim_score:            optim_score = score_test            k_optim = k            p_optim = p_        print("%.5f,%.d,%.d"%(optim_score,k_optim, p_optim))"""#-------------------------TGA------------------------tga = TGA.TGA(n_components=18,trim_proportion=0.1,random_state=1)train_X_TGA = tga.fit_transform(train_X)"""#Predicciones en el testtest_raw = utils.load_test()test = utils.one_hot_encode(df = test_raw.drop(["PassengerId"], axis = 1))colnames = test.columnstest_scaled_array = RobScal.transform(test)test_scaled = pd.DataFrame(test_scaled_array,columns=colnames)knn = KNeighborsClassifier(n_neighbors = k_optim ,p = p_optim).fit(train_X_scaled,train_y)pred_labels = knn.predict(X = test_scaled)predicted_labels = utils.encode_labels(pred_labels)#utils.generate_submission(labels = predicted_labels, method = "knn", notes = "RobScal_k_" + str(k_optim) + "_and_p_" + str(p_optim))"""