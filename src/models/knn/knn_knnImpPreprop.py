import osimport sysMODELS = os.path.abspath(os.path.join(os.path.dirname(__file__), os.pardir))SRC = os.path.abspath(os.path.join(MODELS, os.pardir))sys.path.append(SRC)import utilsimport numpy as npimport pandas as pdfrom sklearn.neighbors import KNeighborsClassifierfrom sklearn.model_selection import cross_validatefrom sklearn.model_selection import GridSearchCVfrom sklearn.preprocessing import Normalizerfrom sklearn.preprocessing import RobustScalerfrom sklearn.preprocessing import OneHotEncodertrain_raw = pd.read_csv('/Users/marcosesquivelgonzalez/Desktop/Master C.Datos/Projects/MDatos_PreprocClasif/Spaceship-Titanic/data/train_pr_KnnImp.csv')train_raw = utils.merge_numerical(train_raw) #PARA MERGEAR LAS COLUMNAS VISTAS EN EDAtrain_X = utils.one_hot_encode(df = train_raw.drop(["Transported", "PassengerId"], axis = 1))RobScal = RobustScaler()df_array = RobScal.fit_transform(train_X)train_X_RobScal = pd.DataFrame(df_array,columns=train_X.columns)train_y = train_raw.Transported"""score_cv = cross_validate(estimator = KNeighborsClassifier(34,                                                                p=1),                              X = train_X_NormScal, y = train_y, cv = 10, n_jobs = -1,return_train_score=True)print("Train score: %.4f %.4f"%(np.mean(score_cv["train_score"]),np.std(score_cv["train_score"])))print("Test score: %.4f %.4f"%(np.mean(score_cv["test_score"]),np.std(score_cv["test_score"])))print(score_cv["test_score"])score_cv = cross_validate(estimator = KNeighborsClassifier(n_neighbors=30,                                                                p=2),                              X = train_X_NormScal, y = train_y, cv = 10, n_jobs = -1,return_train_score=True)print("Train score: %.4f %.4f"%(np.mean(score_cv["train_score"]),np.std(score_cv["train_score"])))print("Test_score: %.4f %.4f"%(np.mean(score_cv["test_score"]),np.std(score_cv["test_score"])))print(score_cv["test_score"])weights = ["uniform", "distance"]knn = KNeighborsClassifier()k_range = list(range(1,100))pgrid = dict(n_neighbors=k_range,p=[1,2])grid = GridSearchCV(knn, pgrid, scoring='accuracy', n_jobs = -1, cv =10, return_train_score=True)grid_search = grid.fit(train_X_scaled,train_y)print(grid_search.best_params_)"""#----------------------------BASTANTE MÁS RÁPIDO ASÍ:(?)-------------------------colnames = train_X.columnsfor p_ in [1,2]:    optim_score = 0.    for k in range(1,100):        score_cv = cross_validate(estimator = KNeighborsClassifier(n_neighbors=k,p = p_),                                          X = train_X_RobScal, y = train_y, cv = 10, n_jobs = -1)                        score_test = np.mean(score_cv["test_score"])                        if score_test > optim_score:            optim_score = score_test            k_optim = k    print("%.5f,%.d,%.d"%(optim_score,k_optim, p_))#Predicciones en el test"""test_raw = pd.read_csv('/Users/marcosesquivelgonzalez/Desktop/Master C.Datos/Projects/MDatos_PreprocClasif/Spaceship-Titanic/data/test_pr_KnnImp.csv')test_raw = utils.merge_numerical(test_raw)test = utils.one_hot_encode(df = test_raw.drop(["PassengerId"], axis = 1))test_scaled_array = RobScal.transform(test)test_scaled = pd.DataFrame(test_scaled_array,columns=test.columns)knn = KNeighborsClassifier(n_neighbors = 31, p = 2).fit(train_X_RobScal,train_y)pred_labels = knn.predict(X = test_scaled)predicted_labels = utils.encode_labels(pred_labels)utils.generate_submission(labels = predicted_labels, method = "knn", notes = "RobScal_k_31_euclid_merged")"""