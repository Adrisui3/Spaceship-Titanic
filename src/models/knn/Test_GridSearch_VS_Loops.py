"""En este script se buscan los valores de k y p óptimos según SCV con 10 folds para el caso de los datos imputadoscon knn, y variables numéricas combianadas como se describió en el EDA. Además, se probó tanto con Robust Scaler como el Normalizer para el preprocesado."""import osimport sysMODELS = os.path.abspath(os.path.join(os.path.dirname(__file__), os.pardir))SRC = os.path.abspath(os.path.join(MODELS, os.pardir))sys.path.append(SRC)import utilsimport numpy as npimport pandas as pdfrom sklearn.neighbors import KNeighborsClassifierfrom sklearn.model_selection import cross_validatefrom sklearn.model_selection import GridSearchCVfrom sklearn.preprocessing import Normalizerfrom sklearn.preprocessing import RobustScalerfrom sklearn.preprocessing import OneHotEncoderimport timetrain_raw = utils.load_train_KnnImp()train_raw = utils.merge_numerical(train_raw) #PARA MERGEAR LAS COLUMNAS VISTAS EN EDAtrain_X = utils.one_hot_encode(df = train_raw.drop(["Transported", "PassengerId"], axis = 1))""" #Si se quiere probar con el normalizer es necesario descomentar estoNormScal = Normalizer()df_array = NormScal.fit_transform(train_X)train_X_NormScal = pd.DataFrame(df_array,columns=train_X.columns)"""RobScal = RobustScaler()df_array = RobScal.fit_transform(train_X)train_X_RobScal = pd.DataFrame(df_array,columns=train_X.columns)train_y = train_raw.Transported#--------------------------GridSeach con CrossValidation start = time.time()knn = KNeighborsClassifier()k_range = list(range(1,60))pgrid = {'n_neighbors':k_range,'p':[1,2]}grid = GridSearchCV(knn, pgrid, scoring='accuracy', n_jobs = -1, cv =10, return_train_score=True)grid_search = grid.fit(train_X_RobScal,train_y)print(grid_search.best_params_)time_taken = time.time() - startprint('Tiempo que tarda gridsearch:',time_taken)#----------------------------BASTANTE MÁS RÁPIDO ASÍ:(?)-------------------------colnames = train_X.columnsstart = time.time()for p_ in [1,2]:    optim_score = 0.    for k in range(1,60):        score_cv = cross_validate(estimator = KNeighborsClassifier(n_neighbors=k,p = p_),                                          X = train_X_RobScal, y = train_y, cv = 10, n_jobs = -1)                        score_test = np.mean(score_cv["test_score"])                        if score_test > optim_score:            optim_score = score_test            k_optim = k    print("%.5f,%.d,%.d"%(optim_score,k_optim, p_))time_taken = time.time() - startprint('Tiempo que tarda for loopings:',time_taken)"""#Predicciones en el testtest_raw = utils.load_test_KnnImp()test_raw = utils.merge_numerical(test_raw)test = utils.one_hot_encode(df = test_raw.drop(["PassengerId"], axis = 1))test_scaled_array = RobScal.transform(test)test_scaled = pd.DataFrame(test_scaled_array,columns=test.columns)knn = KNeighborsClassifier(n_neighbors = 51, p = 1).fit(train_X_RobScal,train_y)pred_labels = knn.predict(X = test_scaled)predicted_labels = utils.encode_labels(pred_labels)utils.generate_submission(labels = predicted_labels, method = "knn", notes = "RobScal_k_51_manh_merged_knnImp")"""