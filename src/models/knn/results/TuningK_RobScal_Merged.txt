#SCV 10 folds, merged, rob_scaler

Distance metric, CV score, k_optim, uniform weights
manhattan 0.8011135801489357 49
euclidean 0.8005382061558404 48
minkowski 0.799618004576538 45
cosine 0.7992702670528947 45
braycurtis 0.800306866129651 46
canberra 0.7884566749996693 29
chebyshev 0.7923685568033015 32
correlation 0.7990401174556566 30
seuclidean 0.7911024694787244 27
mahalanobis 0.7175944076293268 98

Distance metric, CV score, k_optim, weights=distance
manhattan 0.7892615372405858 82
euclidean 0.7876499609803844 86
minkowski 0.7869601735380871 95
cosine 0.787649299630967 34
braycurtis 0.7891452720130154 97
canberra 0.778675978466463 24
chebyshev 0.783623797997434 84
correlation 0.7867276430829465 42
seuclidean 0.7831641601523749 26
mahalanobis 0.7057452746584131 88




0.7361 0.7435 0.76 0.7608 0.7749 0.7768 0.7829 0.7833 0.7904 0.7876 0.7923 0.787 0.7944 0.7866 0.7925 0.7893 0.7932 0.7905 0.7935 0.7912 0.7937 0.7921 0.7937 0.7948 0.7974 0.7948 0.7971 0.7958 0.7965 0.797 0.797 0.7961 0.7965 0.7948 0.7973 0.7972 0.7958 0.7957 0.7956 0.7966 0.7984 0.7981 0.8 0.7982 0.8008 0.8008 0.8008 0.8003 0.8011 0.7998 0.8002 0.799 0.7989 0.7982 0.7984 0.7982 0.7974 0.7982 0.7973 0.797 0.7954 0.7986 0.7963 0.7963 0.7966 0.7972 0.7957 0.7969 0.7955 0.7951 0.7964 0.7967 0.795 0.7943 0.795 0.7958 0.7949 0.7957 0.7958 0.7943 0.7951 0.7952 0.7955 0.794 0.7936 0.7942 0.7944 0.7948 0.7948 0.7946 0.7924 0.7928 0.7951 0.7934 0.7944 0.7951 0.7954 0.7954 0.796 


Para distancia =  manhattan y weights =  uniform
Mejor resultado: 0.8011135801489357  para k= 49 

0.7361 0.7272 0.755 0.7505 0.7648 0.7686 0.7746 0.7753 0.781 0.7801 0.7826 0.7804 0.7827 0.7817 0.7825 0.783 0.7839 0.7839 0.7844 0.7839 0.7842 0.7847 0.785 0.7857 0.7859 0.7858 0.7859 0.7851 0.7852 0.7852 0.7856 0.7849 0.7849 0.7852 0.7851 0.785 0.7844 0.7843 0.7844 0.7852 0.7857 0.7855 0.7868 0.7868 0.7864 0.787 0.7871 0.7872 0.7865 0.7865 0.7864 0.7863 0.7867 0.7871 0.7857 0.7865 0.786 0.786 0.7865 0.7865 0.7865 0.787 0.7872 0.7864 0.7865 0.7868 0.7866 0.7865 0.7867 0.7874 0.7878 0.7885 0.788 0.7881 0.788 0.7879 0.7887 0.7882 0.7882 0.7887 0.7889 0.7893 0.789 0.7883 0.7882 0.788 0.7885 0.7887 0.7887 0.788 0.7887 0.788 0.7887 0.7883 0.7878 0.7879 0.7879 0.7878 0.7881 


Para distancia =  manhattan y weights =  distance
Mejor resultado: 0.7892615372405858  para k= 82 

0.7374 0.7406 0.7613 0.7591 0.774 0.7744 0.7816 0.7799 0.7885 0.7837 0.788 0.7843 0.79 0.7862 0.7891 0.7879 0.791 0.7902 0.7918 0.7924 0.792 0.7921 0.7925 0.792 0.7952 0.7925 0.7949 0.792 0.7951 0.7963 0.7969 0.7957 0.7946 0.795 0.7952 0.7946 0.797 0.795 0.7964 0.7961 0.7977 0.7966 0.7973 0.7956 0.798 0.7988 0.7992 0.8005 0.7989 0.7995 0.7992 0.7981 0.7964 0.797 0.7981 0.7957 0.7969 0.7959 0.7946 0.7947 0.7954 0.7944 0.7941 0.7935 0.7951 0.7958 0.7942 0.7956 0.794 0.7943 0.7944 0.7943 0.7938 0.7927 0.7928 0.7927 0.7925 0.7924 0.7918 0.7934 0.7927 0.7923 0.7937 0.7901 0.7916 0.7923 0.7905 0.791 0.7921 0.7909 0.7928 0.7918 0.7931 0.7925 0.7925 0.7918 0.7939 0.7925 0.7941 


Para distancia =  euclidean y weights =  uniform
Mejor resultado: 0.8005382061558404  para k= 48 

0.7374 0.7284 0.7547 0.75 0.7653 0.7676 0.7752 0.775 0.7796 0.7789 0.7801 0.7793 0.7819 0.7822 0.782 0.781 0.7817 0.7812 0.7825 0.7817 0.7821 0.7833 0.7829 0.7845 0.7845 0.7841 0.7847 0.7854 0.7848 0.7856 0.7843 0.7843 0.7836 0.7829 0.783 0.7837 0.7832 0.7835 0.7828 0.7839 0.7833 0.7843 0.7844 0.7848 0.7837 0.7844 0.7847 0.785 0.7847 0.7851 0.7845 0.7848 0.7855 0.7844 0.7847 0.7848 0.7841 0.785 0.784 0.7844 0.7842 0.7851 0.7849 0.7848 0.7852 0.7855 0.7841 0.7849 0.7855 0.7858 0.7848 0.7857 0.7856 0.7852 0.7852 0.7856 0.7855 0.7864 0.7864 0.7871 0.7867 0.7867 0.7873 0.7874 0.7864 0.7876 0.7867 0.7863 0.7867 0.786 0.7858 0.786 0.7866 0.7871 0.787 0.787 0.7871 0.787 0.7872 


Para distancia =  euclidean y weights =  distance
Mejor resultado: 0.7876499609803844  para k= 86 

0.737 0.7409 0.7603 0.7573 0.7732 0.7719 0.7812 0.7811 0.7878 0.7855 0.7855 0.7858 0.7882 0.7883 0.7898 0.7901 0.7901 0.79 0.791 0.7887 0.7923 0.7901 0.794 0.7911 0.7936 0.7925 0.7946 0.795 0.7957 0.7951 0.7964 0.7969 0.7948 0.795 0.7947 0.7948 0.7956 0.7958 0.7956 0.7975 0.7971 0.7967 0.7989 0.7986 0.7996 0.7989 0.7975 0.7985 0.7996 0.7988 0.7985 0.7994 0.799 0.7985 0.7979 0.7972 0.7971 0.7955 0.7956 0.7955 0.7952 0.7958 0.7948 0.7944 0.7946 0.7939 0.7929 0.7935 0.7927 0.7939 0.7938 0.7925 0.7921 0.7927 0.7928 0.7918 0.7923 0.7918 0.7913 0.7905 0.7916 0.7911 0.7918 0.791 0.7918 0.7908 0.7913 0.7902 0.7917 0.7913 0.7911 0.7917 0.7916 0.7916 0.7932 0.7916 0.794 0.792 0.7927 


Para distancia = Minkowski(p=3)
Mejor resultado: 0.799618004576538  para k= 45 

0.737 0.7279 0.7538 0.7477 0.7658 0.7673 0.7733 0.7764 0.7797 0.7798 0.7774 0.7796 0.7796 0.7816 0.7796 0.7802 0.7804 0.7816 0.7809 0.781 0.7816 0.7821 0.7829 0.7833 0.783 0.7829 0.783 0.7837 0.7835 0.7835 0.7832 0.7833 0.7836 0.7825 0.7825 0.7816 0.7816 0.7827 0.7826 0.7832 0.7824 0.7834 0.784 0.7843 0.7842 0.7839 0.7833 0.7834 0.7843 0.7835 0.7832 0.7841 0.7844 0.7852 0.7841 0.7848 0.7845 0.7842 0.7835 0.7842 0.7853 0.785 0.7858 0.7853 0.7852 0.7845 0.7849 0.7849 0.7856 0.7855 0.7859 0.7858 0.7859 0.785 0.7862 0.7855 0.7862 0.7857 0.7853 0.7857 0.7863 0.7859 0.786 0.7865 0.786 0.7868 0.7862 0.7864 0.786 0.7858 0.7863 0.7865 0.7866 0.787 0.787 0.787 0.7868 0.7867 0.7865 


Para distancia = Minkowski(p=3)
Mejor resultado: 0.7869601735380871  para k= 95 

0.7389 0.7473 0.7667 0.7695 0.7836 0.7798 0.7878 0.7852 0.792 0.7902 0.7927 0.7911 0.792 0.7906 0.7927 0.7916 0.7946 0.7914 0.7974 0.7926 0.7944 0.7936 0.7977 0.7969 0.7979 0.7958 0.7971 0.7956 0.7978 0.799 0.7972 0.7972 0.7972 0.7969 0.7978 0.7972 0.7966 0.7972 0.7971 0.7969 0.799 0.7992 0.799 0.7984 0.7993 0.799 0.798 0.7986 0.7988 0.7989 0.7988 0.7988 0.7981 0.7978 0.7978 0.7975 0.7959 0.7962 0.7951 0.797 0.7948 0.7959 0.7948 0.7972 0.7956 0.7962 0.7947 0.7952 0.7933 0.7935 0.794 0.7941 0.7956 0.7958 0.7958 0.7956 0.7955 0.7957 0.7958 0.7949 0.7944 0.795 0.7954 0.7956 0.7955 0.7954 0.7965 0.7966 0.7962 0.7967 0.7958 0.7954 0.7962 0.7954 0.7962 0.7948 0.796 0.7952 0.7952 


Para distancia =  cosine y weights =  uniform
Mejor resultado: 0.7992702670528947  para k= 45 

0.7389 0.7304 0.7545 0.7605 0.7725 0.7729 0.7766 0.7773 0.7796 0.7802 0.7811 0.7826 0.7836 0.7826 0.7841 0.7834 0.7849 0.7844 0.784 0.7839 0.7848 0.7839 0.7842 0.7847 0.7844 0.7856 0.7857 0.7863 0.7857 0.786 0.7862 0.7868 0.7872 0.7876 0.7865 0.786 0.7862 0.786 0.7865 0.7853 0.7857 0.7855 0.7858 0.7851 0.7856 0.7855 0.7851 0.785 0.7852 0.7859 0.7857 0.7857 0.7859 0.7856 0.7858 0.7862 0.7862 0.7859 0.7858 0.7856 0.7857 0.7853 0.7862 0.786 0.7857 0.7853 0.7855 0.7856 0.7852 0.7853 0.7852 0.7855 0.7855 0.785 0.7851 0.785 0.7856 0.7856 0.7852 0.7851 0.7849 0.785 0.7847 0.7848 0.7847 0.785 0.785 0.7855 0.7852 0.785 0.785 0.7849 0.7849 0.7852 0.7852 0.785 0.7843 0.7842 0.7844 


Para distancia =  cosine y weights =  distance
Mejor resultado: 0.787649299630967  para k= 34 

0.735 0.7431 0.7633 0.7614 0.776 0.776 0.7834 0.7825 0.7929 0.7906 0.7948 0.7903 0.7948 0.7909 0.7949 0.7903 0.7927 0.7921 0.7948 0.7927 0.7941 0.7912 0.7954 0.7931 0.7969 0.7962 0.7967 0.7971 0.798 0.7995 0.7989 0.7982 0.7977 0.7966 0.798 0.7975 0.7983 0.7987 0.7979 0.7977 0.7978 0.7982 0.7982 0.7977 0.7989 0.8003 0.8002 0.7997 0.8001 0.7997 0.7988 0.7994 0.7981 0.7985 0.7981 0.7974 0.7973 0.7981 0.7975 0.7981 0.7973 0.7995 0.7979 0.7987 0.7971 0.7978 0.7967 0.797 0.7962 0.7963 0.7963 0.7977 0.7967 0.7973 0.7956 0.7964 0.795 0.7949 0.7952 0.7942 0.7949 0.7954 0.795 0.7954 0.7961 0.7963 0.7974 0.7951 0.7964 0.7967 0.7979 0.7964 0.7965 0.7973 0.7984 0.7972 0.7975 0.7972 0.7974 


Para distancia =  braycurtis y weights =  uniform
Mejor resultado: 0.800306866129651  para k= 46 

0.735 0.7266 0.7573 0.7514 0.763 0.7699 0.7755 0.7753 0.7789 0.7811 0.7825 0.7819 0.783 0.7817 0.7835 0.7821 0.7837 0.7842 0.7856 0.7845 0.7851 0.7857 0.7862 0.7868 0.7867 0.7873 0.7871 0.7872 0.7872 0.7877 0.7868 0.788 0.787 0.7875 0.7872 0.7874 0.7872 0.7866 0.7855 0.7862 0.7853 0.7863 0.7862 0.785 0.7857 0.7862 0.7859 0.7864 0.7868 0.7865 0.7866 0.7874 0.7864 0.7877 0.7863 0.7875 0.7875 0.7875 0.7875 0.7889 0.7875 0.7881 0.7875 0.7881 0.7878 0.7875 0.7873 0.7873 0.7871 0.7878 0.7876 0.7876 0.7872 0.7881 0.7871 0.7878 0.7876 0.7881 0.7878 0.7879 0.7879 0.7882 0.7885 0.7881 0.7879 0.7882 0.7878 0.7881 0.788 0.7876 0.7881 0.7888 0.7883 0.7882 0.788 0.7886 0.7891 0.789 0.7888 


Para distancia =  braycurtis y weights =  distance
Mejor resultado: 0.7891452720130154  para k= 97 

0.7159 0.7299 0.7447 0.7446 0.7642 0.7595 0.7719 0.7723 0.7795 0.7773 0.7837 0.7775 0.7867 0.7812 0.7851 0.7789 0.7881 0.7798 0.7881 0.7836 0.7855 0.7809 0.7863 0.7836 0.7875 0.7857 0.7883 0.7862 0.7885 0.7875 0.7883 0.7865 0.788 0.7837 0.7878 0.7837 0.7873 0.7839 0.7875 0.784 0.7837 0.7824 0.7856 0.7835 0.7843 0.7826 0.7835 0.782 0.7836 0.7806 0.7827 0.7796 0.7816 0.7816 0.782 0.7796 0.7813 0.7794 0.7802 0.7783 0.7803 0.7783 0.7786 0.7795 0.7798 0.7759 0.777 0.7763 0.7764 0.7765 0.7765 0.7759 0.7763 0.7768 0.7759 0.7765 0.7757 0.7765 0.7753 0.7728 0.7755 0.7729 0.7753 0.774 0.774 0.7706 0.7728 0.7706 0.7714 0.7706 0.7724 0.7695 0.7714 0.7711 0.7722 0.7722 0.7733 0.7732 0.775 


Para distancia =  canberra y weights =  uniform
Mejor resultado: 0.7884566749996693  para k= 29 

0.7159 0.7073 0.7375 0.7338 0.7526 0.7558 0.7629 0.766 0.7703 0.7704 0.7757 0.7744 0.7767 0.7752 0.7756 0.775 0.778 0.7782 0.7784 0.7787 0.7765 0.7769 0.778 0.7787 0.7771 0.778 0.777 0.7764 0.7767 0.7772 0.776 0.7757 0.7744 0.7758 0.7759 0.7753 0.7759 0.7761 0.776 0.7743 0.7746 0.7734 0.7736 0.7736 0.7743 0.773 0.7728 0.772 0.7725 0.7726 0.7723 0.7729 0.7738 0.7733 0.7722 0.7711 0.7718 0.7719 0.7725 0.7717 0.773 0.7717 0.7714 0.7715 0.7721 0.7709 0.7719 0.7709 0.7698 0.77 0.7702 0.7704 0.7699 0.7692 0.7699 0.7688 0.7692 0.7676 0.7684 0.7683 0.7688 0.7688 0.7687 0.7682 0.7684 0.7681 0.7688 0.7682 0.7683 0.7677 0.7674 0.7688 0.768 0.7684 0.7675 0.7686 0.7674 0.7676 0.7671 


Para distancia =  canberra y weights =  distance
Mejor resultado: 0.778675978466463  para k= 24 

0.7285 0.734 0.7575 0.7574 0.7728 0.7711 0.7791 0.7773 0.7843 0.7801 0.7866 0.7776 0.7848 0.7816 0.7874 0.7871 0.7896 0.787 0.7879 0.7872 0.7882 0.7871 0.7906 0.7874 0.7906 0.7868 0.7895 0.79 0.7914 0.7909 0.7921 0.7924 0.7912 0.7918 0.7909 0.7919 0.79 0.789 0.7902 0.7893 0.7887 0.7913 0.7902 0.79 0.7898 0.7909 0.7919 0.7908 0.7905 0.7916 0.7901 0.7909 0.79 0.7902 0.7897 0.787 0.7879 0.7877 0.7873 0.7862 0.7867 0.7864 0.7855 0.7857 0.7851 0.7867 0.7842 0.7828 0.7856 0.7856 0.7852 0.7836 0.7833 0.7826 0.7827 0.7837 0.7834 0.7824 0.7835 0.7833 0.7835 0.7812 0.7821 0.7809 0.7812 0.7793 0.7802 0.7802 0.7807 0.7799 0.7796 0.7802 0.7794 0.7804 0.7818 0.7811 0.7787 0.7791 0.7793 


Para distancia =  chebyshev y weights =  uniform
Mejor resultado: 0.7923685568033015  para k= 32 

0.7285 0.723 0.75 0.7491 0.7627 0.7683 0.7695 0.7712 0.7755 0.7747 0.7758 0.7773 0.7758 0.7766 0.7772 0.778 0.7771 0.7794 0.7784 0.7801 0.7794 0.7809 0.7805 0.7816 0.7803 0.7819 0.7799 0.7817 0.7802 0.7824 0.7819 0.7816 0.781 0.7826 0.7806 0.7818 0.7802 0.7814 0.7816 0.7811 0.7807 0.7825 0.7824 0.7828 0.7811 0.7817 0.7807 0.7822 0.7828 0.7828 0.782 0.7816 0.7814 0.7832 0.7814 0.7825 0.7824 0.7826 0.7821 0.7827 0.7812 0.7827 0.7819 0.7827 0.7811 0.7819 0.782 0.7829 0.7827 0.7817 0.7828 0.7835 0.7825 0.7832 0.7821 0.7826 0.7826 0.782 0.7817 0.7825 0.7822 0.7822 0.7826 0.7836 0.7818 0.7826 0.7821 0.7835 0.7821 0.7827 0.7833 0.7826 0.7825 0.7833 0.7832 0.7821 0.7812 0.7814 0.7813 


Para distancia =  chebyshev y weights =  distance
Mejor resultado: 0.783623797997434  para k= 84 

0.7389 0.7463 0.7684 0.7695 0.785 0.7793 0.7904 0.7839 0.7898 0.7886 0.7912 0.7896 0.7919 0.7878 0.792 0.7895 0.7927 0.7913 0.7967 0.7924 0.7944 0.7937 0.7948 0.7959 0.7978 0.7977 0.7982 0.7972 0.7971 0.799 0.7979 0.7977 0.7962 0.7969 0.7978 0.7973 0.7978 0.7967 0.799 0.7964 0.798 0.7974 0.7979 0.7987 0.7985 0.7985 0.7975 0.7982 0.7989 0.7978 0.7972 0.7974 0.7973 0.7972 0.7984 0.7975 0.7966 0.7984 0.7966 0.7973 0.7948 0.7962 0.7948 0.7959 0.795 0.7952 0.7957 0.7957 0.7958 0.7955 0.7956 0.7955 0.7949 0.7949 0.7949 0.7954 0.7941 0.7946 0.7949 0.7942 0.7933 0.7933 0.7941 0.7923 0.795 0.7942 0.7949 0.7941 0.7958 0.7956 0.7954 0.7956 0.7957 0.7957 0.7952 0.7944 0.7959 0.7944 0.796 


Para distancia =  correlation y weights =  uniform
Mejor resultado: 0.7990401174556566  para k= 30 

0.7389 0.7306 0.7565 0.7604 0.7726 0.7713 0.7774 0.7776 0.7795 0.7806 0.7826 0.7813 0.7822 0.7827 0.7821 0.7824 0.7835 0.7836 0.7837 0.7837 0.7844 0.7842 0.7841 0.785 0.7845 0.7849 0.7852 0.7851 0.7847 0.7844 0.7849 0.7858 0.7858 0.7862 0.786 0.7862 0.7864 0.786 0.7862 0.7864 0.7866 0.7867 0.7863 0.7856 0.7857 0.7851 0.7857 0.7852 0.7857 0.7855 0.7859 0.7856 0.7857 0.7856 0.7858 0.7856 0.786 0.7862 0.7859 0.7857 0.7858 0.7859 0.7857 0.7858 0.7857 0.7855 0.7856 0.7855 0.7858 0.7858 0.7858 0.7858 0.7852 0.7852 0.7855 0.7851 0.7852 0.7849 0.7849 0.7849 0.785 0.7848 0.7847 0.7848 0.7848 0.785 0.7849 0.7848 0.7845 0.7847 0.7849 0.785 0.7843 0.7842 0.7842 0.7843 0.7843 0.7849 0.7851 


Para distancia =  correlation y weights =  distance
Mejor resultado: 0.7867276430829465  para k= 42 

0.7291 0.7389 0.7561 0.7527 0.7687 0.7664 0.7743 0.7755 0.7832 0.7803 0.7836 0.783 0.789 0.7842 0.7874 0.7859 0.7896 0.7855 0.7896 0.7858 0.7877 0.7855 0.7903 0.7851 0.7891 0.785 0.7911 0.7871 0.7879 0.7856 0.7879 0.786 0.7845 0.7827 0.7835 0.7807 0.7827 0.7814 0.7828 0.7812 0.7832 0.7796 0.7818 0.7783 0.7805 0.7795 0.7795 0.7789 0.7801 0.777 0.7794 0.7765 0.7768 0.7742 0.7767 0.7738 0.7737 0.7744 0.7743 0.7749 0.7748 0.7744 0.7725 0.7729 0.7706 0.7701 0.771 0.7701 0.7702 0.7684 0.7707 0.7698 0.7704 0.7689 0.7695 0.7694 0.7691 0.769 0.7683 0.7673 0.768 0.7676 0.7686 0.7677 0.7661 0.7653 0.7649 0.7646 0.7643 0.762 0.7652 0.7619 0.7635 0.762 0.7636 0.763 0.7642 0.7618 0.764 


Para distancia =  seuclidean y weights =  uniform
Mejor resultado: 0.7911024694787244  para k= 27 

0.7291 0.7201 0.7491 0.7455 0.759 0.7626 0.766 0.7691 0.7729 0.7752 0.776 0.7775 0.7782 0.7794 0.7786 0.7795 0.7789 0.7796 0.7798 0.7802 0.7813 0.7819 0.7828 0.7814 0.7817 0.7832 0.7822 0.7825 0.781 0.7826 0.7827 0.7812 0.781 0.7801 0.7799 0.7798 0.779 0.7794 0.7784 0.7789 0.7786 0.7789 0.7797 0.779 0.7784 0.779 0.7788 0.7787 0.7775 0.7786 0.7776 0.7778 0.7774 0.7776 0.777 0.778 0.7766 0.7771 0.7775 0.7768 0.778 0.7765 0.7766 0.7764 0.7772 0.777 0.7772 0.777 0.7768 0.7768 0.7768 0.7764 0.7763 0.7756 0.7757 0.7752 0.7757 0.7764 0.7764 0.7766 0.7752 0.7755 0.7751 0.7759 0.7756 0.7757 0.776 0.7751 0.7746 0.7742 0.7737 0.7726 0.7732 0.7727 0.7725 0.7725 0.773 0.7722 0.7727 


Para distancia =  seuclidean y weights =  distance
Mejor resultado: 0.7831641601523749  para k= 26 

0.6325 0.6371 0.6481 0.6595 0.6677 0.6739 0.6723 0.6785 0.681 0.6847 0.6793 0.687 0.6868 0.6894 0.6862 0.6906 0.6894 0.6945 0.6922 0.6964 0.6953 0.7017 0.6957 0.7032 0.6987 0.7047 0.7006 0.7046 0.704 0.709 0.7039 0.7091 0.7039 0.7085 0.7028 0.7085 0.7057 0.7115 0.7054 0.7101 0.7069 0.7129 0.709 0.7127 0.7084 0.7132 0.7085 0.7115 0.7077 0.7139 0.7112 0.7148 0.7087 0.7141 0.7082 0.7114 0.7061 0.7107 0.7066 0.7106 0.7078 0.7105 0.7083 0.7133 0.7115 0.7148 0.7117 0.7154 0.7116 0.7144 0.711 0.7149 0.712 0.7145 0.712 0.7146 0.7124 0.7161 0.713 0.716 0.7122 0.716 0.7139 0.716 0.7133 0.7144 0.7136 0.7148 0.7139 0.7155 0.7145 0.7155 0.7143 0.7155 0.714 0.7151 0.7144 0.7176 0.7151 


Para distancia =  mahalanobis y weights =  uniform
Mejor resultado: 0.7175944076293268  para k= 98 

0.6325 0.6243 0.6491 0.654 0.6655 0.6677 0.6734 0.6741 0.6755 0.677 0.6757 0.678 0.6793 0.6812 0.6824 0.6817 0.6831 0.685 0.6848 0.6854 0.6863 0.6868 0.6881 0.6891 0.6896 0.6908 0.6912 0.6925 0.6933 0.693 0.694 0.6938 0.6949 0.6938 0.6929 0.6954 0.6957 0.6962 0.6969 0.6954 0.6965 0.698 0.6994 0.6977 0.7 0.6993 0.7001 0.6987 0.6994 0.6988 0.7005 0.7 0.7006 0.6984 0.6996 0.6998 0.7015 0.7009 0.7014 0.7005 0.7021 0.7017 0.7017 0.7022 0.7021 0.7015 0.7016 0.7017 0.7025 0.7024 0.7016 0.7022 0.7019 0.7029 0.7017 0.7024 0.703 0.7024 0.703 0.7041 0.7037 0.704 0.7051 0.7038 0.7051 0.7046 0.7053 0.7057 0.7056 0.7055 0.7051 0.7044 0.704 0.7032 0.704 0.7044 0.7041 0.7047 0.7046 


Para distancia =  mahalanobis y weights =  distance
Mejor resultado: 0.7057452746584131  para k= 88 